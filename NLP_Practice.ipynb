{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOvt1UTmljOZpdIW3SRpqNE"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["***TOKENIZATION***"],"metadata":{"id":"FrvAaebDI0Yb"}},{"cell_type":"markdown","source":["LINE TOKENIZATION"],"metadata":{"id":"J5y9lv3-Ju5w"}},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_fE-9PBBIe3e","executionInfo":{"status":"ok","timestamp":1742568075917,"user_tz":-330,"elapsed":17,"user":{"displayName":"DIVYA DAGA","userId":"18186686349820229381"}},"outputId":"c7b45b2f-a58e-46a7-aac4-5fb188693ee9"},"outputs":[{"output_type":"stream","name":"stdout","text":["['welcome to great Learning.', 'I am very happy.']\n"]},{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n","[nltk_data]   Package punkt_tab is already up-to-date!\n"]}],"source":["import nltk\n","\n","# Download the 'punkt_tab' resource\n","nltk.download('punkt_tab')\n","\n","data=\"welcome to great Learning. I am very happy.\"\n","tokens=nltk.sent_tokenize(data)\n","print(tokens)"]},{"cell_type":"markdown","source":["WORD TOKENIZATION"],"metadata":{"id":"5pt0_cxxJ4w7"}},{"cell_type":"code","source":["tokens=nltk.word_tokenize(data)\n","print(tokens)\n","#tokens.count-> will give error\n","type(tokens)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jNPJya23JzdU","executionInfo":{"status":"ok","timestamp":1742568230580,"user_tz":-330,"elapsed":30,"user":{"displayName":"DIVYA DAGA","userId":"18186686349820229381"}},"outputId":"61968869-76bd-4b3d-894d-ffc46fca1f2d"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["['welcome', 'to', 'great', 'Learning', '.', 'I', 'am', 'very', 'happy', '.']\n"]},{"output_type":"execute_result","data":{"text/plain":["list"]},"metadata":{},"execution_count":8}]},{"cell_type":"code","source":["len(tokens)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3hAk1K2OKR2c","executionInfo":{"status":"ok","timestamp":1742568241875,"user_tz":-330,"elapsed":20,"user":{"displayName":"DIVYA DAGA","userId":"18186686349820229381"}},"outputId":"9761693d-964c-400e-d8f3-29a56b5e6070"},"execution_count":9,"outputs":[{"output_type":"execute_result","data":{"text/plain":["10"]},"metadata":{},"execution_count":9}]},{"cell_type":"markdown","source":["***STEMMING***:\n","Stemming is the way to reduce word to its word stem that affixes tosuffixes and prefixes."],"metadata":{"id":"c4FYWxDDKCAn"}},{"cell_type":"code","source":["#importing modules\n","from nltk.stem import PorterStemmer\n","from nltk.tokenize import word_tokenize\n","\n","#initializing the stemmer\n","portstem=PorterStemmer()\n","\n","#Choose wordsto be stemmed\n","words=[\"program\",\"programs\",\"programer\",\"programing\",\"programers\"]\n","\n","for w in words:\n","  print(w,\":\",portstem.stem(w))\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"EhQawiRXKzgv","executionInfo":{"status":"ok","timestamp":1742568613993,"user_tz":-330,"elapsed":60,"user":{"displayName":"DIVYA DAGA","userId":"18186686349820229381"}},"outputId":"53d28fc3-cd00-49d4-ee07-5f6d92c101be"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["program : program\n","programs : program\n","programer : program\n","programing : program\n","programers : program\n"]}]},{"cell_type":"markdown","source":["***LEMMATIZATON***:\n","It helps to do morphological analysis of the words. Help us retrieve information about the deailed dictionaries which the algorithm can refer to link the form back to its lemma."],"metadata":{"id":"TSYrW1m2L1GI"}},{"cell_type":"code","source":["nltk.download('wordnet')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bEKZGQyMLzwT","executionInfo":{"status":"ok","timestamp":1742568892136,"user_tz":-330,"elapsed":188,"user":{"displayName":"DIVYA DAGA","userId":"18186686349820229381"}},"outputId":"b4d1fb45-17ca-4fd7-d962-80c485bd82a5"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package wordnet to /root/nltk_data...\n"]},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":11}]},{"cell_type":"code","source":["#importing modules\n","from nltk.stem import WordNetLemmatizer\n","\n","#initializing the stemmer\n","Lemmatizer=WordNetLemmatizer()\n","\n","#Choose wordsto be lemmatize\n","print(\"rocks :\",Lemmatizer.lemmatize(\"rocks\"))\n","print(\"corpora :\",Lemmatizer.lemmatize(\"corpora\"))\n","print(\"cacti :\",Lemmatizer.lemmatize(\"cacti\"))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8p2mQHZkMzaS","executionInfo":{"status":"ok","timestamp":1742569065975,"user_tz":-330,"elapsed":4985,"user":{"displayName":"DIVYA DAGA","userId":"18186686349820229381"}},"outputId":"39f00ea6-5b73-49d0-df38-a769f8567c42"},"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["rocks : rock\n","corpora : corpus\n","cacti : cactus\n"]}]},{"cell_type":"markdown","source":["***REMOVING STOP WORDS***\n","Stop words are common words that occur in entences that add weight to the sentence. They act as a bridge and ensure that sentences are grammatically correct. These are filtered out before processing natural language data and is pre-processing method."],"metadata":{"id":"zvAVMpuKN6kO"}},{"cell_type":"code","source":["from nltk.corpus import stopwords\n","nltk.download('stopwords')\n","\n","data=\"\"\" Data science is one of the most trendind field to work with. It needs data to give prediction by using the past scenarios.\"\"\"\n","stopWords=set(stopwords.words('english'))\n","words=word_tokenize(data)\n","wordsFiltered=[]\n","\n","for w in words:\n","  if w in stopWords:\n","    wordsFiltered.append(w)\n","\n","print(wordsFiltered)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GAax6lQ2N6Em","executionInfo":{"status":"ok","timestamp":1742569687296,"user_tz":-330,"elapsed":17,"user":{"displayName":"DIVYA DAGA","userId":"18186686349820229381"}},"outputId":"55c24ebc-870a-4111-ae77-1b9ada8bd19b"},"execution_count":16,"outputs":[{"output_type":"stream","name":"stdout","text":["['is', 'of', 'the', 'most', 'to', 'with', 'to', 'by', 'the']\n"]},{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Package stopwords is already up-to-date!\n"]}]},{"cell_type":"markdown","source":["***MODELLING TECHNIQUES IN NLP***"],"metadata":{"id":"EpBHXOvDVMJt"}},{"cell_type":"markdown","source":["BAG OF WORDS:\n","This model is used to preprocess the text or documentations. It converts the documents into a baag of words, which keeps a count of total occurences ofost frequently used words. Used to transform tokens into features."],"metadata":{"id":"DT5m8XKEVRJ_"}},{"cell_type":"markdown","source":["TF-IDF:\n","->Term frequency and nverse document frequency\n","->Measures score in order to get information retrieval(IR).\n","-> Used ot reflects how relevant a term is.\n","->Procedure to calculate TF-IDF:\n","1) how many times a word appears in a document\n","2) IDF of the word across a set of documents\n","TF= frequency of term/ total number of terms\n","IDF= log[total number of documnets/number of documents containg the term]"],"metadata":{"id":"JnSKhVMpWUL_"}},{"cell_type":"markdown","source":["WORD EMBEDDING:\n","These are vectors and one of the most common way to encode words as vectors of numbers those vectors can be fed into ML models for inference and also helps to establish distance between tokens.\n","types:\n","1) Word2vec\n","2) Glove\n","3) fastText"],"metadata":{"id":"b6GjgzsGY6Ol"}}]}